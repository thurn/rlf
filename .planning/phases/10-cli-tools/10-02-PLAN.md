---
phase: 10-cli-tools
plan: 02
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - crates/rlf-cli/src/commands/eval.rs
  - crates/rlf-cli/src/commands/mod.rs
  - crates/rlf-cli/src/main.rs
autonomous: true

must_haves:
  truths:
    - "User can run `rlf eval --lang en --template '{greeting}'` and see evaluated text"
    - "User can pass parameters with `-p name=value` flags"
    - "User can load phrase definitions from a file with `--phrases`"
    - "JSON output includes the result string"
  artifacts:
    - path: "crates/rlf-cli/src/commands/eval.rs"
      provides: "Eval command implementation"
      contains: "pub fn run_eval"
  key_links:
    - from: "crates/rlf-cli/src/commands/eval.rs"
      to: "rlf::Locale"
      via: "Locale::with_language and eval_str"
      pattern: "Locale::with_language"
    - from: "crates/rlf-cli/src/commands/eval.rs"
      to: "rlf::Value"
      via: "parameter conversion to Value"
      pattern: "Value::from"
---

<objective>
Implement the `rlf eval` subcommand for template evaluation.

Purpose: Allow developers to evaluate RLF templates from the command line, useful for testing and debugging localization strings without writing Rust code.

Output: Working `rlf eval` command that evaluates templates with specified language and parameters.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-cli-tools/10-CONTEXT.md
@.planning/phases/10-cli-tools/10-RESEARCH.md
@.planning/phases/10-cli-tools/10-01-SUMMARY.md
@crates/rlf/src/lib.rs
@crates/rlf/src/interpreter/locale.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement eval command</name>
  <files>
    crates/rlf-cli/src/commands/eval.rs
    crates/rlf-cli/src/commands/mod.rs
    crates/rlf-cli/src/main.rs
  </files>
  <action>
1. Create commands/eval.rs:

EvalArgs struct with clap::Args derive:
- --lang <lang> (required): Language code for evaluation
- --template <template> (required): Template string to evaluate
- --phrases <file> (optional): PathBuf to phrase definitions file
- -p/--param <name>=<value> (repeatable): Parameters via parse_key_val function
- --json flag: Output as JSON

Helper function parse_key_val(s: &str) -> Result<(String, String), String>:
- Find '=' position
- Split into (key, value)
- Return error if no '=' found

2. Implement run_eval(args: EvalArgs) -> miette::Result<i32>:

a) Create Locale with specified language:
   - Locale::with_language(&args.lang)

b) If --phrases provided:
   - Load translations with locale.load_translations_str(&args.lang, &content)
   - Handle file read errors with miette::miette!
   - Handle parse errors by converting to miette diagnostic

c) Convert parameters to HashMap<String, Value>:
   - Try parsing value as i64 first (for numeric parameters)
   - Fall back to String if not numeric
   - Use Value::from() for conversion

d) Evaluate template:
   - Call locale.eval_str(&args.template, params)
   - Handle EvalError with miette::miette! conversion

e) Output result:
   - JSON mode: serde_json::json!({ "result": result.to_string() })
   - Human mode: println!("{}", result)

f) Return exitcode::OK on success, exitcode::DATAERR on eval error

3. Update commands/mod.rs:
   - Add eval module
   - Add Eval(EvalArgs) to Commands enum

4. Update main.rs dispatch:
   - Add Commands::Eval(args) => commands::eval::run_eval(args)
  </action>
  <verify>
```bash
# Test simple template (no phrases needed for plain text)
cargo run -p rlf-cli -- eval --lang en --template "Hello World"

# Create test phrases file
echo 'greeting = "Hello";
count(n) = "{n} items";' > /tmp/phrases.rlf

# Test with phrases
cargo run -p rlf-cli -- eval --lang en --phrases /tmp/phrases.rlf --template "{greeting}"

# Test with parameter
cargo run -p rlf-cli -- eval --lang en --phrases /tmp/phrases.rlf --template "{count(n)}" -p n=5

# Test JSON output
cargo run -p rlf-cli -- eval --lang en --template "Test" --json

# Test error case (undefined phrase)
cargo run -p rlf-cli -- eval --lang en --template "{undefined}"

# Test help
cargo run -p rlf-cli -- eval --help
```
  </verify>
  <done>
Eval command evaluates templates with language, loads phrases from file, accepts parameters, outputs JSON or plain text.
  </done>
</task>

</tasks>

<verification>
Run complete test sequence:
```bash
# Plain template
cargo run -p rlf-cli -- eval --lang en --template "Plain text" && echo "OK"

# With phrases file
echo 'hello = "Hello, World!";
greet(name) = "Hello, {name}!";
items(n) = { one: "1 item", other: "{n} items" };' > /tmp/test.rlf

cargo run -p rlf-cli -- eval --lang en --phrases /tmp/test.rlf --template "{hello}"
# Expected: Hello, World!

cargo run -p rlf-cli -- eval --lang en --phrases /tmp/test.rlf --template "{greet(name)}" -p name=Alice
# Expected: Hello, Alice!

# Multiple parameters
cargo run -p rlf-cli -- eval --lang en --phrases /tmp/test.rlf --template "{name} has {n} items" -p name=Bob -p n=42
# Expected: Bob has 42 items

# JSON output
cargo run -p rlf-cli -- eval --lang en --template "Result" --json
# Expected: { "result": "Result" }
```
</verification>

<success_criteria>
- CLI-05: --lang specifies evaluation language
- CLI-06: --template provides template string to evaluate
- CLI-07: -p/--param allows repeatable parameter passing (name=value)
- CLI-08: --phrases loads phrase definitions from file
- Parameters parsed as numbers when possible, strings otherwise
- Errors reported clearly with exit code
</success_criteria>

<output>
After completion, create `.planning/phases/10-cli-tools/10-02-SUMMARY.md`
</output>
